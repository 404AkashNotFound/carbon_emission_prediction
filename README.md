# 🌱 CO₂ Emission Prediction Using Machine Learning  
**Edunet Foundation – AICTE Virtual Internship Project**

---

## 👋 About the Project

This project was built as part of the **AICTE Virtual Internship Program** in collaboration with **Edunet Foundation**. The goal?  
To **analyze global environmental and economic data** and build **machine learning models** that can **predict CO₂ emissions** of different countries based on a wide range of factors.

We’re talking data science meets climate change — with a dash of Excel and a sprinkle of regression trees.

---

## 🌍 The Dataset

We used the **Climate Change Data** from the **World Bank Group**, a rich and publicly available dataset covering most countries from **1990 to 2011**.

It includes all kinds of useful information:

### 🔑 Key Data Categories:
- 🌫️ Greenhouse gases (CO₂, CH₄, N₂O, etc.)
- 👨‍👩‍👧‍👦 Population stats (total, urban, growth rate)
- 💰 Economy (GDP, GNI, FDI)
- 🌾 Agriculture & land (cereal yield, protected areas)
- ☁️ Climate (rainfall, natural disasters)
- ⚡ Energy use
- 🏥 Healthcare (medical personnel counts)
- …and much more!

The diversity of data gives us a great playground to explore relationships and trends around CO₂ emissions.

---

## 🧭 Project Breakdown

We divided the work into **two main phases**:

### 1️⃣ Data Cleaning & Preparation
- Filled in missing values
- Cleaned up weird outliers
- Converted formats (because Excel always has surprises)
- Selected meaningful features

### 2️⃣ Data Exploration & Predictive Modeling
- Visualized patterns and trends
- Found correlations between country features and emissions
- Built and evaluated multiple ML models like:
  - Linear Regression
  - Decision Trees & Random Forest
  - XGBoost (because why not go fancy?)
- Evaluated performance using R², MAE, RMSE, etc.
- Visualized model predictions and compared them to actual data

---

## 🧰 Tools & Tech Used

- **Python** (the hero of the story)
- **Pandas** & **NumPy** for data wrangling
- **Matplotlib** & **Seaborn** for visualizations
- **Scikit-learn** & **XGBoost** for modeling
- **Jupyter Notebook** for development
- **Excel** for some initial poking around
